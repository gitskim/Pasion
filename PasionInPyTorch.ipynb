{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PasionInPyTorch.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R6Dg3hILwpt",
        "colab_type": "code",
        "outputId": "4e68a149-74c6-4752-c184-86ab7a5c2429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "!wget https://github.com/gitskim/Pasion/raw/master/diving.mat\n",
        "!wget https://raw.githubusercontent.com/gitskim/Pasion/master/Diving.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-02 00:23:58--  https://github.com/gitskim/Pasion/raw/master/diving.mat\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/gitskim/Pasion/master/diving.mat [following]\n",
            "--2019-09-02 00:24:00--  https://raw.githubusercontent.com/gitskim/Pasion/master/diving.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9591612 (9.1M) [application/octet-stream]\n",
            "Saving to: ‘diving.mat.1’\n",
            "\n",
            "diving.mat.1        100%[===================>]   9.15M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-09-02 00:24:00 (65.8 MB/s) - ‘diving.mat.1’ saved [9591612/9591612]\n",
            "\n",
            "--2019-09-02 00:24:01--  https://raw.githubusercontent.com/gitskim/Pasion/master/Diving.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6139 (6.0K) [text/plain]\n",
            "Saving to: ‘Diving.txt.1’\n",
            "\n",
            "Diving.txt.1        100%[===================>]   6.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-09-02 00:24:01 (130 MB/s) - ‘Diving.txt.1’ saved [6139/6139]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrkE1eEVRP0p",
        "colab_type": "text"
      },
      "source": [
        "# READ: http://www.cs.virginia.edu/~vicente/vislang/notebooks/pytorch-lab.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgm9gmgb5Opo",
        "colab_type": "text"
      },
      "source": [
        "# READ\n",
        "https://discuss.pytorch.org/t/example-of-many-to-one-lstm/1728/11\n",
        "\n",
        "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/2%20-%20Upgraded%20Sentiment%20Analysis.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP4jyZ1-Zd5s",
        "colab_type": "code",
        "outputId": "3ee7138a-5e88-4625-c6eb-ff7f97b2a4aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import subprocess\n",
        "import numpy as np\n",
        "import os.path\n",
        "import pickle\n",
        "import scipy.io as sio\n",
        "\n",
        "# TODO:\n",
        "# ANNOTATION_FILE = '/home/suhyunkim011/Pasion/Diving.txt'\n",
        "ANNOTATION_FILE = 'Diving.txt'\n",
        "\n",
        "# MAT_FILE = '/home/suhyunkim011/Pasion/diving.mat'\n",
        "MAT_FILE = 'diving.mat'\n",
        "\n",
        "\n",
        "def get_pose_labels2():\n",
        "    # move the pictures to a certain directory and create labels\n",
        "    contents = sio.loadmat(MAT_FILE)\n",
        "    # print(len(contents))\n",
        "    tracked = contents['boxes_tracked_wholevideo']\n",
        "    # print(tracked)\n",
        "    # print(len(tracked))\n",
        "    # (298387, 107)\n",
        "    # print(tracked.shape)\n",
        "\n",
        "    # print(tracked[0].shape)\n",
        "\n",
        "    # batchsize = 298387; timesteps = 202; shape = 104;\n",
        "    arr_frame = []\n",
        "    arr_score = np.array([])\n",
        "    arr_score_flat = []\n",
        "    arr_difficulty = np.array([])\n",
        "    arr_difficulty_flat = []\n",
        "\n",
        "    with open(ANNOTATION_FILE) as filename:\n",
        "        max_counter = 202\n",
        "        group_counter = 0\n",
        "        one_group_counter = 0\n",
        "        supposed_to_be_counter = 0\n",
        "        for line in filename:\n",
        "            #print(line)\n",
        "            if '#' in line:\n",
        "                continue\n",
        "\n",
        "            if 'A' in line:\n",
        "\n",
        "                group_counter += 1\n",
        "                line_arr = line.split()\n",
        "                # print(line_arr[0])\n",
        "                # print(line_arr[1])\n",
        "                start = -1\n",
        "                end = -1\n",
        "\n",
        "                for i in range(0, 2):\n",
        "                    if i == 0:\n",
        "                        start = line_arr[0]\n",
        "                        start = int(start)\n",
        "\n",
        "                    elif i == 1:\n",
        "                        end = line_arr[1]\n",
        "                        end = int(end)\n",
        "\n",
        "                start = start - 1\n",
        "\n",
        "                pose_group = np.zeros([202, 104])\n",
        "\n",
        "                for i in range(start, end + 1):\n",
        "                    supposed_to_be_counter += 1\n",
        "                    converted = tracked[i][:104]\n",
        "                    #print(f\"one_group_counter: {one_group_counter}, converted.shape: {converted.shape}\")\n",
        "                    \n",
        "                    pose_group[one_group_counter, :] = converted\n",
        "                 \n",
        "                    one_group_counter += 1\n",
        "\n",
        "                if one_group_counter > max_counter:\n",
        "                    max_counter = one_group_counter\n",
        "                    print(\"-------------*********---------WARNING: Max counter changed: %d-------------*********\",\n",
        "                          max_counter)\n",
        "                # len(pose_group): 169; one_group_counter: 169; max_one_group_counter: 202\n",
        "\n",
        "                # print(pose_group)\n",
        "                arr_frame.append(\n",
        "                    pose_group)  # figure out why it worked when I put it above the if one_group_counter > max_one_group_counter:\n",
        "                one_group_counter = 0\n",
        "\n",
        "            if 'Score' in line:\n",
        "                line_arr = line.split()\n",
        "                arr_sub_total_score = np.empty(max_counter)\n",
        "                arr_sub_total_score.fill(float(line_arr[2]))\n",
        "\n",
        "                arr_sub_difficulty_score = np.empty(max_counter)\n",
        "                arr_sub_difficulty_score.fill(float(line_arr[3]))\n",
        "\n",
        "                arr_score = np.append(arr_score, arr_sub_total_score)\n",
        "                arr_difficulty = np.append(arr_difficulty, arr_sub_difficulty_score)\n",
        "                # print(arr_sub_total_score)\n",
        "\n",
        "                arr_score_flat.append(float(line_arr[2]))\n",
        "                arr_difficulty_flat.append(float(line_arr[3]))\n",
        "\n",
        "        # print(f'arr_frame: {len(arr_frame)}, arr_score_flat: {len(arr_score_flat)}, arr_difficulty_concat: {len(arr_difficulty_flat)}')\n",
        "        # print(f'arr_frame: {len(arr_frame)}')\n",
        "        # print(arr_frame[71])\n",
        "        print(np.array(arr_frame).shape)\n",
        "    return np.array(arr_frame), np.array(arr_score_flat), arr_difficulty_flat\n",
        "\n",
        "\n",
        "arr_frames, arr_scores, arr_difficulty = get_pose_labels2()\n",
        "print(arr_frames.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159, 202, 104)\n",
            "(159, 202, 104)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkj9UM-QUxbb",
        "colab_type": "text"
      },
      "source": [
        "NOTE: drop_out probability is only used if the number of layers is greater than 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qdj2k5kWkEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "def pearsonr(x, y):\n",
        "    \"\"\"\n",
        "    Mimics `scipy.stats.pearsonr`\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    x : 1D torch.Tensor\n",
        "    y : 1D torch.Tensor\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    r_val : float\n",
        "        pearsonr correlation coefficient between x and y\n",
        "    \n",
        "    Scipy docs ref:\n",
        "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
        "    \n",
        "    Scipy code ref:\n",
        "        https://github.com/scipy/scipy/blob/v0.19.0/scipy/stats/stats.py#L2975-L3033\n",
        "    Example:\n",
        "        >>> x = np.random.randn(100)\n",
        "        >>> y = np.random.randn(100)\n",
        "        >>> sp_corr = scipy.stats.pearsonr(x, y)[0]\n",
        "        >>> th_corr = pearsonr(torch.from_numpy(x), torch.from_numpy(y))\n",
        "        >>> np.allclose(sp_corr, th_corr)\n",
        "    \"\"\"\n",
        "    mean_x = torch.mean(x)\n",
        "    mean_y = torch.mean(y)\n",
        "    xm = x.sub(mean_x)\n",
        "    ym = y.sub(mean_y)\n",
        "    r_num = xm.dot(ym)\n",
        "    r_den = torch.norm(xm, 2) * torch.norm(ym, 2)\n",
        "    r_val = r_num / r_den\n",
        "    return r_val\n",
        "\n",
        "def corrcoef(x):\n",
        "    \"\"\"\n",
        "    Mimics `np.corrcoef`\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    x : 2D torch.Tensor\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    c : torch.Tensor\n",
        "        if x.size() = (5, 100), then return val will be of size (5,5)\n",
        "\n",
        "    Numpy docs ref:\n",
        "        https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html\n",
        "    Numpy code ref: \n",
        "        https://github.com/numpy/numpy/blob/v1.12.0/numpy/lib/function_base.py#L2933-L3013\n",
        "\n",
        "    Example:\n",
        "        >>> x = np.random.randn(5,120)\n",
        "        # result is a (5,5) matrix of correlations between rows\n",
        "        >>> np_corr = np.corrcoef(x)\n",
        "        >>> th_corr = corrcoef(torch.from_numpy(x))\n",
        "        >>> np.allclose(np_corr, th_corr.numpy())\n",
        "        # [out]: True\n",
        "    \"\"\"\n",
        "    # calculate covariance matrix of rows\n",
        "    mean_x = torch.mean(x, 1)\n",
        "    xm = x.sub(mean_x.expand_as(x))\n",
        "    c = xm.mm(xm.t())\n",
        "    c = c / (x.size(1) - 1)\n",
        "\n",
        "    # normalize covariance matrix\n",
        "    d = torch.diag(c)\n",
        "    stddev = torch.pow(d, 0.5)\n",
        "    c = c.div(stddev.expand_as(c))\n",
        "    c = c.div(stddev.expand_as(c).t())\n",
        "\n",
        "    # clamp between -1 and 1\n",
        "    # probably not necessary but numpy does it\n",
        "    c = torch.clamp(c, -1.0, 1.0)\n",
        "\n",
        "    return c\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv2VbgmJjXG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ed8443ef-1eee-4742-d915-008af60d5fc0"
      },
      "source": [
        "sequence_length = 202\n",
        "batch_size = 159\n",
        "\n",
        "class PoseLSTM(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size=104, hidden_size=256, num_layers=1, drop_prob=0.5, lr=0.001, output_size=1):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.drop_prob = drop_prob\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.lr = lr\n",
        "    self.input_size = input_size\n",
        "    self.lstm = nn.LSTM(input_size=self.input_size, \n",
        "                        hidden_size=self.hidden_size, \n",
        "                        num_layers=self.num_layers, \n",
        "                        dropout=self.drop_prob, \n",
        "                        batch_first=True)\n",
        "    # why is there an extra dropout layer when there is dropout in lstm?\n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    \n",
        "  def forward(self, x, hidden):\n",
        "    lstm_output, hidden = self.lstm(x, hidden)\n",
        "    # print(f\"suhyun-{lstm_output.shape}\") [159, 202, 256]\n",
        "    # stacking up the outputs of the LSTM\n",
        "    lstm_out = lstm_output.contiguous().view(-1, self.hidden_size)\n",
        "    nondropped = self.dropout(lstm_out)\n",
        "    output = self.fc(nondropped)\n",
        "    # print(f\"suhyun-lstm-fc: {output.shape}\") [32118, 1]\n",
        "    # return the last output for each batch\n",
        "    output = output.view(batch_size, -1)\n",
        "    # print(f'output: {output.shape}') [159, 202]\n",
        "    output = output[:, -1]\n",
        "    # print(f'forward returns: {output.shape}') [159]\n",
        "    return output, hidden\n",
        "  \n",
        "  # An LSTM has a hidden and a cell state that are saved as a tupel hidden.\n",
        "  # \n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    \n",
        "    if (train_on_gpu):\n",
        "      hidden = (weight.new(self.num_layers, batch_size, self.num_hidden).zero_().cuda(),\n",
        "               weight.new(self.num_layers, batch_size, self_num_hidden).zero_().cuda())\n",
        "      \n",
        "    else:\n",
        "      hidden = (weight.new(self.num_layers, batch_size, self.num_hidden).zero_(),\n",
        "             weight.new(self.num_layers, batch_size, self_num_hidden).zero_())\n",
        "      \n",
        "    return hidden\n",
        "  \n",
        "  \n",
        "  \n",
        "model = PoseLSTM()\n",
        "print(model)\n",
        "pose_estimation = torch.FloatTensor(arr_frames)\n",
        "labels = torch.FloatTensor(arr_scores)\n",
        "\n",
        "epochs=3\n",
        "criterion = pearsonr\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# print(labels.shape)\n",
        "# print(model_output.shape)\n",
        "# print(model_output[0])\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  # batch is not separated, because the size is small enough and I need to full gradient descent. \n",
        "\n",
        "  # initialize hidden state\n",
        "  h = model.init_hidden(159)\n",
        "  \n",
        "  # creating new variables for the hidden state, otherwise we'd backprop\n",
        "  # through the entire training history\n",
        "  h = tuple([each.data for each in h])\n",
        "  \n",
        "  # 0. clear gradients\n",
        "  model.zero_grad()\n",
        "  \n",
        "  # 1. get the output from the model\n",
        "  model_output, h = model.forward(pose_estimation, h)\n",
        "  \n",
        "  # 2. calculate the loss\n",
        "  loss = criterion(model_output, labels)\n",
        "  print(\"hi\")\n",
        "  # 3. call loss.backward()\n",
        "  loss.backward()\n",
        "  \n",
        "  # 4. update the parameters\n",
        "  optimizer.step()\n",
        "  "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PoseLSTM(\n",
            "  (lstm): LSTM(104, 256, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n",
            "hi\n",
            "hi\n",
            "hi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6luTkR4zoG4p",
        "colab_type": "code",
        "outputId": "033edf6a-c1c5-4be6-f5f6-fae2e7214a36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "hidden_state = 256\n",
        "sequence = 202\n",
        "batch_size = 159\n",
        "output_size = 1\n",
        "\n",
        "output = torch.randn([batch_size, sequence, hidden_state])\n",
        "print(output.shape)\n",
        "layer = nn.Linear(hidden_state, output_size)\n",
        "aoutput = layer(output)\n",
        "print(aoutput.shape)\n",
        "\n",
        "#ideal_output = [159, 1]\n",
        "mod = output.contiguous().view(-1, hidden_state)\n",
        "print(mod.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([159, 202, 256])\n",
            "torch.Size([159, 202, 1])\n",
            "torch.Size([32118, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr1vYG8cuNKl",
        "colab_type": "code",
        "outputId": "31dd03e1-1b02-4bad-ad15-52c295dcb663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "layer2 = nn.Linear(hidden_state, output_size)\n",
        "result = layer2(mod)\n",
        "print(result.shape)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32118, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g36ojAze5jN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}